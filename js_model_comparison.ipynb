{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d80d3f7d",
   "metadata": {},
   "source": [
    "# Comparison of Image Classification models and algorithms in Amazon SageMaker JumpStart "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d422b206",
   "metadata": {},
   "source": [
    "---\n",
    "At times, when you are solving a business problem using machine learning (ML), you might want to use multiple ML algorithms and compare them against each other to see which model gives you the best results on dimensions that you care about - model accuracy, inference time, and training time.\n",
    "\n",
    "In this notebook, we demonstrate how you can compare multiple image classification models and algorithms offered by SageMaker JumpStart on dimensions such as model accuracy, inference time, and training time. Models in JumpStart are brought from hubs such as TensorFlow Hub and PyTorch Hub, and training scripts (algorithms) were written separately for each of these frameworks. In this notebook, you can also alter some of the hyper-parameters and examine their effect on the results. \n",
    "\n",
    "Image Classification refers to classifying an image to one of the class labels in the training dataset.\n",
    "\n",
    "Amazon [SageMaker JumpStart](https://docs.aws.amazon.com/sagemaker/latest/dg/studio-jumpstart.html) offers a large suite of ML algorithms. You can use JumpStart to solve many Machine Learning tasks through one-click in SageMaker Studio, or through [SageMaker JumpStart API](https://sagemaker.readthedocs.io/en/stable/overview.html#use-prebuilt-models-with-sagemaker-jumpstart). \n",
    "\n",
    "Note: This notebook was tested on ml.t3.medium instance in Amazon SageMaker Studio with Python 3 (Data Science) kernel and in Amazon SageMaker Notebook instance with conda_python3 kernel.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c59ed72",
   "metadata": {},
   "source": [
    "1. [Set Up](#1.-Set-Up)\n",
    "2. [Specify training and validation data paths](#2.-Specify-training-and-validation-data-paths)\n",
    "3. [Set hyper-parameters](#3.-Hyper-parameters)\n",
    "4. [List of models to run](#4.-Specify-models-to-run)\n",
    "5. [Helper functions](#5.-Helper-functions)\n",
    "6. [Run all models](#6.-Run-all-models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14244a1a",
   "metadata": {},
   "source": [
    "## 1. Set-Up\n",
    "***\n",
    "Before executing the notebook, there are some initial steps required for setup. This notebook requires latest version of sagemaker and ipywidgets.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849f548c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sagemaker ipywidgets --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d54072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker, boto3, json\n",
    "from sagemaker import get_execution_role\n",
    "import boto3, uuid\n",
    "import pandas as pd\n",
    "\n",
    "aws_role = get_execution_role()\n",
    "aws_region = boto3.Session().region_name\n",
    "sess = sagemaker.Session()\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "# unique id to connect all runs\n",
    "# if you run this notebook multiple times, this master id helps you \n",
    "# save each run's results as a separate csv file\n",
    "master_uuid = str(uuid.uuid4())\n",
    "print(\"master id for this run: \", master_uuid)\n",
    "\n",
    "# Lists to store results\n",
    "nameList = []\n",
    "accList = []\n",
    "timeList = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d8ea6c",
   "metadata": {},
   "source": [
    "## 2. Specify training and validation data paths\n",
    "***\n",
    "Training and validation data needs to be stored in the format specified below\n",
    "- A directory with as many sub-directories as the number of classes. \n",
    "    - Each sub-directory should have images belonging to that class in .jpg format. \n",
    "    \n",
    "The input directory should look like below if \n",
    "the training data contains images from two classes: roses and dandelion.\n",
    "\n",
    "    input_directory\n",
    "        |--roses\n",
    "            |--abc.jpg\n",
    "            |--def.jpg\n",
    "        |--dandelion\n",
    "            |--ghi.jpg\n",
    "            |--jkl.jpg\n",
    "\n",
    "We provide tf_flowers dataset as an example dataset for training and validation. This is only for illutration purpose. When you use this notebook, you need to replace the bucket and prefix references below with your own buckets containing separate datasets for training and validation.\n",
    "\n",
    "tf_flower comprises images of five types of flowers. \n",
    "The dataset has been downloaded from [TensorFlow](https://www.tensorflow.org/datasets/catalog/tf_flowers). \n",
    "[Apache 2.0 License](https://jumpstart-cache-prod-us-west-2.s3-us-west-2.amazonaws.com/licenses/Apache-License/LICENSE-2.0.txt).\n",
    "Citation:\n",
    "<sub><sup>\n",
    "@ONLINE {tfflowers,\n",
    "author = \"The TensorFlow Team\",\n",
    "title = \"Flowers\",\n",
    "month = \"jan\",\n",
    "year = \"2019\",\n",
    "url = \"http://download.tensorflow.org/example_images/flower_photos.tgz\" }\n",
    "</sup></sub> source: [TensorFlow Hub](model_url). \n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b208e373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set references to training data\n",
    "training_data_bucket = f\"jumpstart-cache-prod-{aws_region}\"\n",
    "training_data_prefix = \"training-datasets/tf_flowers\"\n",
    "\n",
    "# Set references to validation data\n",
    "validation_data_bucket = f\"jumpstart-cache-prod-{aws_region}\"\n",
    "validation_data_prefix = \"training-datasets/tf_flowers\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5e89ff",
   "metadata": {},
   "source": [
    "## 3. Hyper-parameters\n",
    "As explained above, you can modify the three hyper-parameters shown below and examine their effect on the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53fd3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting below hyper-parameters for this run\n",
    "\n",
    "# Number of epochs\n",
    "EPOCHS = \"5\"\n",
    "\n",
    "# Learning rate\n",
    "LR = \"0.001\"\n",
    "\n",
    "# Batch size\n",
    "BATCH_SIZE = \"16\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65437528",
   "metadata": {},
   "source": [
    "## 4. Specify models to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37840b13-1736-497d-9f09-d521a7d1806c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.jumpstart.notebook_utils import list_jumpstart_models\n",
    "\n",
    "# All available models in JumpStart can be see through this code\n",
    "# We are showing only the top five models for illustration purpose\n",
    "\n",
    "filter_value = \"task == ic\"\n",
    "ic_models = list_jumpstart_models(filter=filter_value)\n",
    "\n",
    "print(\"Total image classification models available in JumpStart: \", len(ic_models))\n",
    "print()\n",
    "print(\"Showing five image classification models from JumpStart: \\n\", ic_models[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f6c086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We picked arbitraraily four models. You can replace the list below with other models\n",
    "\n",
    "# The number of models you add to this list shouldn't exceed the number of training and inference instances\n",
    "# available to your account in SageMaker, as all these models will be trained and inferred in parallel\n",
    "models = [\"tensorflow-ic-imagenet-mobilenet-v2-075-224-classification-4\", \n",
    "          \"tensorflow-ic-imagenet-inception-v3-classification-4\", \n",
    "          \"pytorch-ic-googlenet\",\n",
    "          \"pytorch-ic-alexnet\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5cc860",
   "metadata": {},
   "source": [
    "## 5. Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4946500d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Function to query the endpoint\n",
    "def query_endpoint(img, endpoint_name):\n",
    "    client = boto3.client('runtime.sagemaker')\n",
    "    response = client.invoke_endpoint(EndpointName=endpoint_name, ContentType='application/x-image', Body=img, Accept='application/json;verbose')\n",
    "    return response\n",
    "\n",
    "# Function to parse predicion response\n",
    "def parse_prediction(query_response):\n",
    "    model_predictions = json.loads(query_response['Body'].read())\n",
    "    predicted_label = model_predictions['predicted_label']\n",
    "    labels = model_predictions['labels']\n",
    "    probabilities = model_predictions['probabilities']\n",
    "    return predicted_label, probabilities, labels \n",
    "\n",
    "# Function that returns all files under a given S3 bucket prefix\n",
    "def listS3Files(bucket, prefix):\n",
    "    file_prefix = []\n",
    "    file_name = []\n",
    "    s3 = boto3.resource('s3')\n",
    "    my_bucket = s3.Bucket(bucket)\n",
    "    for object_summary in my_bucket.objects.filter(Prefix=prefix):\n",
    "        if object_summary.key[-1] != \"/\": # don't append parent directory name\n",
    "            file_prefix.append(object_summary.key)\n",
    "            split = object_summary.key.split(\"/\")\n",
    "            file_name.append(split[-1])\n",
    "    return file_prefix\n",
    "\n",
    "# Function to calculate model accuracy\n",
    "# It will calculate validation accuracy if you supply a validation dataset in the setting above\n",
    "from sklearn.metrics import accuracy_score\n",
    "def calcModelAccuracy(endpoint_name, bucket, file_prefixes):\n",
    "    #maximum images to test against\n",
    "    size = 100\n",
    "    if len(file_prefixes)<size: size = len(file_prefixes)\n",
    "    actual_labels = []\n",
    "    pred_labels = []\n",
    "    for fp in file_prefixes[0:size]:\n",
    "        if not fp.endswith(\".jpg\"): continue\n",
    "        s3.download_file(bucket, f\"{fp}\", \"temp.jpg\")\n",
    "        actual_label = fp.split(\"/\")[-2]\n",
    "        with open(\"temp.jpg\", 'rb') as file: img = file.read()\n",
    "        query_response = query_endpoint(img, endpoint_name)\n",
    "        predicted_label, probabilities, labels = parse_prediction(query_response)\n",
    "        actual_labels.append(actual_label)\n",
    "        pred_labels.append(predicted_label)\n",
    "        \n",
    "    acc = accuracy_score(actual_labels, pred_labels)\n",
    "    os.remove(\"temp.jpg\")\n",
    "    return acc\n",
    "\n",
    "# This function downloads validation images to help measure inference time\n",
    "def downloadImages(bucket, file_prefixes, size):\n",
    "    images = []\n",
    "    total_files = len(file_prefixes)\n",
    "    if total_files==0: return images\n",
    "    # download images randomly from validation set\n",
    "    count = 0\n",
    "    for i in range(size):\n",
    "        num = random.randrange(total_files)\n",
    "        fp = file_prefixes[num]\n",
    "        # find file extension to make sure it is an image\n",
    "        result = fp.split(\".\")\n",
    "        if len(result)==0: continue\n",
    "        fext = result[-1].lower()\n",
    "        if fext in [\"jpg\", \"jpeg\", \"png\", \"bmp\"]:\n",
    "            fname = f\"temp-{count}.jpg\"\n",
    "            s3.download_file(bucket, fp, fname)\n",
    "            with open(fname, 'rb') as file: img = file.read()\n",
    "            images.append(img)\n",
    "            count += 1\n",
    "            os.remove(fname)\n",
    "    return images\n",
    "\n",
    "# Function to measure inference-time\n",
    "# This function measures the time it takes to make an inference for all the supplied images\n",
    "# and reports inference time per image in milliseconds (msec)\n",
    "def timeIT(images, endpoint_name):\n",
    "    if len(images)==0: return None\n",
    "    start_time = time.time()\n",
    "    for img in images:\n",
    "        query_response = query_endpoint(img, endpoint_name)\n",
    "    time_taken = (time.time() - start_time)/len(images)*1000 # converting to msec\n",
    "    return time_taken\n",
    "\n",
    "# Functions to save results\n",
    "import pandas as pd\n",
    "def writeResults(name, accuracy, time):\n",
    "    nameList.append(name)\n",
    "    accList.append(accuracy)\n",
    "    timeList.append(time)\n",
    "    \n",
    "# This function saves the results\n",
    "def saveResults():\n",
    "    df = pd.DataFrame({\"model-name\": nameList, \"accuracy\": accList, \"time-per-inference (msec)\": timeList})\n",
    "    csv_fn = f\"./{master_uuid[0:8]}-{EPOCHS}-{LR}-{BATCH_SIZE}.csv\"\n",
    "    df.to_csv(csv_fn, index=False)\n",
    "    return csv_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d881c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import image_uris, model_uris, script_uris, hyperparameters\n",
    "from sagemaker.tuner import ContinuousParameter\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.utils import name_from_base\n",
    "from sagemaker.tuner import HyperparameterTuner\n",
    "\n",
    "# Function to finetune the model. It uses \"ml.p3.8xlarge\" as a training instance.\n",
    "# Here, we retrieve the training docker container, the training algorithm source, \n",
    "# the pre-trained base model, and a python dictionary of the training hyper-parameters \n",
    "# that the algorithm accepts with their default values. Note that the model_version=\"*\" \n",
    "# fetches the latest model. Also, we do need to specify the training_instance_type to fetch train_image_uri.\n",
    "def fineTuneModel(model_id):\n",
    "    model_version = \"*\"\n",
    "    uuid = master_uuid[0:8]\n",
    "    training_job_name = f\"jumpstart-example-train-model-compare-{uuid}-{model_id}-FT\"\n",
    "    training_instance_type = \"ml.p3.8xlarge\"\n",
    "\n",
    "    train_image_uri = image_uris.retrieve(\n",
    "        region=None,\n",
    "        framework=None,\n",
    "        model_id=model_id,\n",
    "        model_version=model_version,\n",
    "        image_scope=\"training\",\n",
    "        instance_type=training_instance_type,\n",
    "    )\n",
    "    # Retrieve the training script\n",
    "    train_source_uri = script_uris.retrieve(\n",
    "        model_id=model_id, model_version=model_version, script_scope=\"training\"\n",
    "    )\n",
    "    # Retrieve the pre-trained model tarball to further fine-tune\n",
    "    train_model_uri = model_uris.retrieve(\n",
    "        model_id=model_id, model_version=model_version, model_scope=\"training\"\n",
    "    )\n",
    "\n",
    "    #There are two kinds of parameters that need to be set for training.\n",
    "    # The first one are the parameters for the training job. These include: (i) Training data path. \n",
    "    # This is S3 folder in which the input data is stored, \n",
    "    # (ii) Output path: This the s3 folder in which the training output is stored. \n",
    "    # (iii) Training instance type: This indicates the type of machine on which to run the training. \n",
    "    # Typically, we use GPU instances for these training. We defined the training instance type \n",
    "    # above to fetch the correct train_image_uri.\n",
    "    # The second set of parameters are algorithm specific training hyper-parameters.\n",
    "    \n",
    "    training_dataset_s3_path = f\"s3://{training_data_bucket}/{training_data_prefix}\"\n",
    "\n",
    "    output_bucket = sess.default_bucket()\n",
    "    output_prefix = uuid + \"-jumpstart-example-ic-training-\" + model_id\n",
    "\n",
    "    s3_output_location = f\"s3://{output_bucket}/{output_prefix}/output\"\n",
    "\n",
    "    # Retrieve the default hyper-parameters for fine-tuning the model\n",
    "    hps = hyperparameters.retrieve_default(model_id=model_id, model_version=model_version)\n",
    "\n",
    "    # [Optional] Override default hyperparameters with custom values\n",
    "    hps[\"epochs\"] = EPOCHS\n",
    "    hps[\"adam-learning-rate\"] = LR\n",
    "    hps[\"batch-size\"] = BATCH_SIZE\n",
    "\n",
    "    # Create SageMaker Estimator instance\n",
    "    ic_estimator = Estimator(\n",
    "        role=aws_role,\n",
    "        image_uri=train_image_uri,\n",
    "        source_dir=train_source_uri,\n",
    "        model_uri=train_model_uri,\n",
    "        entry_point=\"transfer_learning.py\",\n",
    "        instance_count=1,\n",
    "        instance_type=training_instance_type,\n",
    "        max_run=360000,\n",
    "        hyperparameters=hps,\n",
    "        output_path=s3_output_location,\n",
    "        base_job_name=training_job_name,\n",
    "    )\n",
    "\n",
    "    # Launch a SageMaker Training job by passing s3 path of the training data\n",
    "    ic_estimator.fit({\"training\": training_dataset_s3_path}, logs=True, wait=False)\n",
    "        \n",
    "    training_job_name = ic_estimator.latest_training_job.name\n",
    "    estimator = ic_estimator\n",
    "    return training_job_name, estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bcacfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to deploy a fine tune model. Model is deployed to a \"ml.p3.2xlarge\" instance\n",
    "# A trained model does nothing on its own. We now want to use the model to perform inference. \n",
    "# For this example, that means predicting the class label of an image. \n",
    "# Run inference on the pre-trained model. We start by retrieving the artifacts for deploying an endpoint.\n",
    "\n",
    "def deployFineTunedModel(model_id, ic_estimator):\n",
    "    model_version = \"*\"\n",
    "    uuid = master_uuid[0:8]\n",
    "    inference_instance_type = \"ml.p3.2xlarge\"\n",
    "\n",
    "    # Retrieve the inference docker container uri\n",
    "    deploy_image_uri = image_uris.retrieve(\n",
    "        region=None,\n",
    "        framework=None,\n",
    "        image_scope=\"inference\",\n",
    "        model_id=model_id,\n",
    "        model_version=model_version,\n",
    "        instance_type=inference_instance_type,\n",
    "    )\n",
    "    # Retrieve the inference script uri\n",
    "    deploy_source_uri = script_uris.retrieve(\n",
    "        model_id=model_id, model_version=model_version, script_scope=\"inference\"\n",
    "    )\n",
    "\n",
    "    endpoint_name = name_from_base(f\"jumpstart-example-infer-model-compare-{model_id}-\")\n",
    "\n",
    "    # Use the estimator to deploy to a SageMaker endpoint\n",
    "    finetuned_predictor = (ic_estimator).deploy(\n",
    "        initial_instance_count=1,\n",
    "        instance_type=inference_instance_type,\n",
    "        entry_point=\"inference.py\",\n",
    "        image_uri=deploy_image_uri,\n",
    "        source_dir=deploy_source_uri,\n",
    "        endpoint_name=endpoint_name,\n",
    "        wait = False\n",
    "    )\n",
    "    \n",
    "    return endpoint_name, finetuned_predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4139a7e0",
   "metadata": {},
   "source": [
    "## 6. Run all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1101828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run all models\n",
    "import time\n",
    "\n",
    "# get file prefixes for all validation data files and download inference images\n",
    "INF_TEST_NUM_IMAGES = 100\n",
    "val_file_prefixes = listS3Files(validation_data_bucket, validation_data_prefix)\n",
    "images = downloadImages(validation_data_bucket, val_file_prefixes, INF_TEST_NUM_IMAGES)\n",
    "\n",
    "def run():\n",
    "    uuid = master_uuid[0:8]\n",
    "    client = boto3.client('sagemaker')\n",
    "        \n",
    "    # fine-tuned training\n",
    "    tjNames = []\n",
    "    estimators = []\n",
    "    for model_id in models:\n",
    "        training_job_name, ic_estimator = fineTuneModel(model_id)\n",
    "        tjNames.append(training_job_name)\n",
    "        estimators.append(ic_estimator)\n",
    "        time.sleep(10)\n",
    "        \n",
    "    while(True):\n",
    "        count = 0\n",
    "        for tj in tjNames:\n",
    "            response = client.describe_training_job(TrainingJobName=tj)\n",
    "            print(response['TrainingJobStatus'])\n",
    "            if (response['TrainingJobStatus']=='Completed'):\n",
    "                count += 1\n",
    "                print(\"training job completed: \" + tj)\n",
    "        if count==len(tjNames): break\n",
    "        time.sleep(60)\n",
    "        \n",
    "    # fine tuned deploy\n",
    "    endpoints = []\n",
    "    predictors = []\n",
    "    for i in range(len(models)):\n",
    "        model_id = models[i]\n",
    "        ep, pred = deployFineTunedModel(model_id, estimators[i])\n",
    "        endpoints.append(ep)\n",
    "        predictors.append(pred)\n",
    "        \n",
    "    while(True):\n",
    "        count = 0\n",
    "        for ep in endpoints:\n",
    "            response = client.describe_endpoint(EndpointName=ep)\n",
    "            print(response['EndpointStatus'])\n",
    "            if (response['EndpointStatus']=='InService'):\n",
    "                count += 1\n",
    "                print(\"endpoint in service\" + ep)\n",
    "        if count==len(endpoints): break\n",
    "        time.sleep(60)\n",
    "            \n",
    "    for i in range(len(models)):\n",
    "        print(\"making inferences for model: \" + models[i])\n",
    "        name = uuid + \"-\" + models[i] + \"-FT\"\n",
    "        accuracy = calcModelAccuracy(endpoints[i], validation_data_bucket, val_file_prefixes)\n",
    "        mytime = timeIT(images, endpoints[i])\n",
    "        writeResults(name, accuracy, mytime)\n",
    "        predictors[i].delete_model()\n",
    "        predictors[i].delete_endpoint()\n",
    "        \n",
    "    # Save results to a csv file\n",
    "    csv_fn = saveResults()\n",
    "    return csv_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b6f3ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_fn = run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357e11e1-df93-4c85-a3a8-321b6bce61ea",
   "metadata": {},
   "source": [
    "### Results are shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978878e4-1e77-46c5-9559-879ba1aa3b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(csv_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512f1d39-35be-4a4d-9888-994a01ea39e7",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1a1eee-b4c6-48ee-80da-445490e6423e",
   "metadata": {},
   "source": [
    "In this post, we demonstrated how to use JumpStart to build high performing image classification models on multiple dimensions of interest, such as model accuracy, training time, and inference latency. We provided the code to run this exercise on your own dataset; you can pick any models of interest that are presently available for image classification in the JumpStart model hub. You can obtain training times from SageMaker console under Training / Training Jobs. We encourage you to give it a try today. For more details on JumpStart, refer to [SageMaker JumpStart](https://docs.aws.amazon.com/sagemaker/latest/dg/studio-jumpstart.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa456c0d-745e-4524-ad1b-7e099643a5e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
